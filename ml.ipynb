# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
df = pd.read_csv('/content/loan_prediction_data - loan_approval_dataset.csv.csv')

# Data Preprocessing
# Drop unnecessary columns or handle missing values as needed
df = df.drop(['loan_id'], axis=1)  # Drop loan_id if not needed
df = df.dropna()  # Drop rows with missing values

# Convert categorical variables to numerical using Label Encoding
label_columns = ['education', 'self_employed']
label_encoder = LabelEncoder()
for column in label_columns:
    df[column] = label_encoder.fit_transform(df[column])

# Feature scaling
scaler = StandardScaler()
scaled_features = scaler.fit_transform(df.drop('loan_status', axis=1))

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(scaled_features, df['loan_status'], test_size=0.2, random_state=42)

# Model training
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# Model evaluation
y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Classification Report
print('\nClassification Report:\n', classification_report(y_test, y_pred))

# Save the trained model to a file using joblib
import joblib
joblib.dump(model, 'loan_approval_model.joblib')

print("Model saved successfully.")
